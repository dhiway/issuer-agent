"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.isIContent = exports.fromSchemaAndContent = exports.fromNestedSchemaAndContent = exports.verify = exports.verifyDataStructure = exports.verifyDisclosedAttributes = exports.hashContents = exports.toJsonLD = void 0;
const tslib_1 = require("tslib");
const util_1 = require("@polkadot/util");
const utils_1 = require("@cord.network/utils");
const Did = tslib_1.__importStar(require("@cord.network/did"));
const Schema = tslib_1.__importStar(require("../schema/index.js"));
const VC_VOCAB = 'https://www.w3.org/2018/credentials/v1';
/**
 * Produces JSON-LD readable representations of [[IContent]]['contents']. This is done by implicitly or explicitely transforming property keys to globally unique predicates.
 * Where possible these predicates are taken directly from the Verifiable Credentials vocabulary. Properties that are unique to a [[Schema]] are transformed to predicates by prepending the [[Schema]][schema][$id].
 *
 * @param content A (partial) [[IContent]] from to build a JSON-LD representation from. The `identifier` property is required.
 * @param expanded Return an expanded instead of a compacted represenation. While property transformation is done explicitely in the expanded format, it is otherwise done implicitly via adding JSON-LD's reserved `@context` properties while leaving [[IContent]][contents] property keys untouched.
 * @returns An object which can be serialized into valid JSON-LD representing an [[IContent]]'s ['contents'].
 */
function jsonLDcontents(content, expanded = true) {
    const { schemaId, contents, holder } = content;
    if (!schemaId)
        new utils_1.SDKErrors.SchemaIdentifierMissingError();
    const vocabulary = `${schemaId}#`;
    const result = {};
    if (holder)
        result['@id'] = holder;
    if (!expanded) {
        return {
            ...utils_1.jsonabc.sortObj(result),
            '@context': { '@vocab': vocabulary },
            ...utils_1.jsonabc.sortObj(contents ?? {}),
        };
    }
    Object.entries(contents || {}).forEach(([key, value]) => {
        let val = value;
        if (typeof value === 'object') {
            /* FIXME: GH-issue #40 */
            /* Supporting object inside is tricky, and jsonld expansion is even more harder */
            /* for now, we got things under control with this check but need more work here */
            let newObj = {};
            Object.entries(utils_1.jsonabc.sortObj(value)).forEach(([k, v]) => {
                newObj[vocabulary + k] = v;
            });
            val = newObj;
        }
        result[vocabulary + key] = val;
    });
    return result;
}
/**
 * Produces JSON-LD readable representations of the content. This is done by implicitly or explicitly transforming property keys to globally unique predicates.
 * Where possible these predicates are taken directly from the Verifiable Credentials vocabulary. Properties that are unique to a [[Schema]] are transformed to predicates by prepending the [[Schema]][schema][$id].
 *
 * @param claim A (partial) [[IContent]] from to build a JSON-LD representation from. The `identifier` property is required.
 * @param expanded Return an expanded instead of a compacted representation. While property transformation is done explicitly in the expanded format, it is otherwise done implicitly via adding JSON-LD's reserved `@context` properties while leaving [[IContent]][contents] property keys untouched.
 * @returns An object which can be serialized into valid JSON-LD representing an [[IContent]].
 */
function toJsonLD(content, expanded = true) {
    const credentialSubject = jsonLDcontents(content, expanded);
    const prefix = expanded ? VC_VOCAB : '';
    const result = {
        [`${prefix}credentialSubject`]: credentialSubject,
    };
    result[`${prefix}credentialSchema`] = {
        '@id': content.schemaId,
    };
    if (!expanded)
        result['@context'] = { '@vocab': VC_VOCAB };
    return result;
}
exports.toJsonLD = toJsonLD;
function makeStatementsJsonLD(content) {
    const normalized = jsonLDcontents(content, true);
    return Object.entries(normalized).map(([key, value]) => JSON.stringify({ [key]: value }));
}
/**
 * Produces salted hashes of individual statements comprising a (partial) [[IContent]] to enable selective disclosure of contents. Can also be used to reproduce hashes for the purpose of validation.
 *
 * @param content Full or partial [[IContent]] to produce statement hashes from.
 * @param options Object containing optional parameters.
 * @param options.canonicalisation Canonicalisation routine that produces an array of statement strings from the [IContent]. Default produces individual `{"key":"value"}` JSON representations where keys are transformed to expanded JSON-LD.
 * @param options.nonces Optional map of nonces as produced by this function.
 * @param options.nonceGenerator Nonce generator as defined by [[hashStatements]] to be used if no `nonces` are given. Default produces random UUIDs (v4).
 * @param options.hasher The hasher to be used. Required but defaults to 256 bit blake2 over `${nonce}${statement}`.
 * @returns An array of salted `hashes` and a `nonceMap` where keys correspond to unsalted statement hashes.
 */
function hashContents(content, options = {}) {
    // apply defaults
    const defaults = { canonicalisation: makeStatementsJsonLD };
    const canonicalisation = options.canonicalisation || defaults.canonicalisation;
    // use canonicalisation algorithm to make hashable statement strings
    const statements = canonicalisation(content);
    // iterate over statements to produce salted hashes
    const processed = utils_1.Crypto.hashStatements(statements, options);
    // produce array of salted hashes to add to credential
    const hashes = processed
        .map(({ saltedHash }) => saltedHash)
        .sort((a, b) => (0, util_1.hexToBn)(a).cmp((0, util_1.hexToBn)(b)));
    // produce nonce map, where each nonce is keyed with the unsalted hash
    const nonceMap = {};
    processed.forEach(({ digest, nonce, statement }) => {
        // throw if we can't map a digest to a nonce - this should not happen if the nonce map is complete and the credential has not been tampered with
        if (!nonce)
            throw new utils_1.SDKErrors.ContentNonceMapMalformedError(statement);
        nonceMap[digest] = nonce;
    }, {});
    return { hashes, nonceMap };
}
exports.hashContents = hashContents;
/**
 * Used to verify the hash list based proof over the set of disclosed attributes in [[Content]].
 *
 * @param content Full or partial [[IContent]] to verify proof against.
 * @param proof Proof consisting of a map that matches nonces to statement digests and the resulting hashes.
 * @param proof.nonces A map where a statement digest as produces by options.hasher is mapped to a nonce.
 * @param proof.hashes Array containing hashes which are signed into the credential. Should result from feeding statement digests and nonces in proof.nonce to options.hasher.
 * @param options Object containing optional parameters.
 * @param options.canonicalisation Canonicalisation routine that produces an array of statement strings from the [IContent]. Default produces individual `{"key":"value"}` JSON representations where keys are transformed to expanded JSON-LD.
 * @param options.hasher The hasher to be used. Required but defaults to 256 bit blake2 over `${nonce}${statement}`.
 */
function verifyDisclosedAttributes(content, proof, options = {}) {
    // apply defaults
    const defaults = { canonicalisation: makeStatementsJsonLD };
    const canonicalisation = options.canonicalisation || defaults.canonicalisation;
    const { nonces } = proof;
    // use canonicalisation algorithm to make hashable statement strings
    const statements = canonicalisation(content);
    // iterate over statements to produce salted hashes
    const hashed = utils_1.Crypto.hashStatements(statements, { ...options, nonces });
    // check resulting hashes
    const digestsInProof = Object.keys(nonces);
    const { verified, errors } = hashed.reduce((status, { saltedHash, statement, digest, nonce }) => {
        // check if the statement digest was contained in the proof and mapped it to a nonce
        if (!digestsInProof.includes(digest) || !nonce) {
            status.errors.push(new utils_1.SDKErrors.NoProofForStatementError(statement));
            return { ...status, verified: false };
        }
        // check if the hash is whitelisted in the proof
        if (!proof.hashes.includes(saltedHash)) {
            status.errors.push(new utils_1.SDKErrors.InvalidProofForStatementError(statement));
            return { ...status, verified: false };
        }
        return status;
    }, { verified: true, errors: [] });
    if (verified !== true) {
        throw new utils_1.SDKErrors.ContentUnverifiableError('One or more statements in the content could not be verified', { cause: errors });
    }
}
exports.verifyDisclosedAttributes = verifyDisclosedAttributes;
/**
 *  Checks whether the input meets all the required criteria of an [[IContent]] object.
 *  Throws on invalid input.
 *
 * @param input The potentially only partial IContent.
 *
 */
function verifyDataStructure(input) {
    if (!input.schemaId) {
        throw new utils_1.SDKErrors.SchemaIdentifierMissingError();
    }
    if ('holder' in input) {
        Did.validateUri(input.holder, 'Did');
    }
    if (input.contents !== undefined) {
        Object.entries(input.contents).forEach(([key, value]) => {
            if (!key ||
                typeof key !== 'string' ||
                !['string', 'number', 'boolean', 'object'].includes(typeof value)) {
                throw new utils_1.SDKErrors.InputContentsMalformedError();
            }
        });
    }
    utils_1.DataUtils.validateId(utils_1.Identifier.uriToIdentifier(input.schemaId), 'Identifier');
}
exports.verifyDataStructure = verifyDataStructure;
/**
 * Verifies the data structure and schema of a Claim.
 *
 * @param inputContent IContent to verify.
 * @param schema ISchema to verify inputContent.
 */
function verify(inputContent, schema) {
    Schema.verifyContentAganistSchema(inputContent.contents, schema);
    verifyDataStructure(inputContent);
}
exports.verify = verify;
/**
 * Builds a [[Content]] stream from [[IContent]] and nested [[ISchema]]s.
 *
 * @param schema A [[Schema]] object that has nested [[Schema]]s.
 * @param nestedSchemas The array of [[Schema]]s, which are used inside the main [[Schema]].
 * @param contents The data inside the [[Content]].
 * @param holder The holder of the [[Content]].
 *
 * @returns A validated [[Content]] stream.
 */
function fromNestedSchemaAndContent(schema, nestedSchemas, contents, holder, issuer) {
    Schema.verifyContentAgainstNestedSchemas(schema, nestedSchemas, contents);
    const content = {
        schemaId: schema.$id,
        contents: contents,
        holder: holder,
        issuer: issuer,
    };
    verifyDataStructure(content);
    return content;
}
exports.fromNestedSchemaAndContent = fromNestedSchemaAndContent;
/**
 * Builds a new Content stream from [[ISchema]], IContent['contents'] and issuer's [[DidUri]].
 *
 * @param schema [[ISchema]] on which the content is based on.
 * @param contents IContent['contents'] to be used as the data of the instantiated Content stream.
 * @param holder The DID to be used as the holder.
 * @returns A Content object.
 */
function fromSchemaAndContent(schema, contents, holder, issuer) {
    Schema.verifyDataStructure(schema);
    Schema.verifyContentAganistSchema(contents, schema);
    const content = {
        schemaId: schema.$id,
        contents: contents,
        holder: holder,
        issuer: issuer,
    };
    verifyDataStructure(content);
    return content;
}
exports.fromSchemaAndContent = fromSchemaAndContent;
/**
 *  Custom Type Guard to determine input being of type IContent
 *
 * @param input The potentially only partial IContent.
 *
 * @returns Boolean whether input is of type IContent.
 */
function isIContent(input) {
    try {
        verifyDataStructure(input);
    }
    catch (error) {
        return false;
    }
    return true;
}
exports.isIContent = isIContent;
